# coding=utf-8
"""
å®ä½“æŠ½å–æ¨¡å— - ä¸“é—¨ç”¨äºä»LLMå›ç­”ä¸­æå–éŸ³ä¹ç›¸å…³ä¸‰å…ƒç»„ (head, relation, tail)
é€šè¿‡æŸ¥è¯¢çŸ¥è¯†å›¾è°±è·å–å·²çŸ¥å®ä½“åˆ—è¡¨ï¼Œå¹¶ç»“åˆè§„åˆ™ä¸å¤§æ¨¡å‹è¿›è¡Œæ··åˆæŠ½å–ã€‚

æ ¸å¿ƒç›®æ ‡ï¼šå‡†ç¡®æŠ½å–å‡ºå¦‚ ("ä¸ƒé‡Œé¦™", "æ­Œæ‰‹", "å‘¨æ°ä¼¦") çš„ç»“æ„åŒ–äº‹å®ï¼Œ
ä»¥ä¾¿ä¸KGæ¯”å¯¹ï¼Œæ£€æµ‹å¹»è§‰ã€‚
"""
from db import get_db, close_db
import re
import subprocess
import sys
import json
from typing import List, Dict, Tuple


# ==============================================================================
# ğŸ§  ç±»ï¼šMusicEntityExtractor â€”â€” éŸ³ä¹é¢†åŸŸå®ä½“è¯å…¸åŠ è½½ä¸åŒ¹é…å™¨
# ä½œç”¨ï¼šä» Neo4j çŸ¥è¯†å›¾è°±ä¸­ä¸€æ¬¡æ€§åŠ è½½æ‰€æœ‰å·²çŸ¥å®ä½“ï¼ˆæ­Œæ›²/ä¸“è¾‘/äººç‰©ï¼‰ï¼Œ
#       å¹¶æä¾›åŸºäºæœ€å¤§åŒ¹é…ï¼ˆlongest-firstï¼‰çš„å®ä½“è¯†åˆ«æ–¹æ³•ã€‚
# è®¾è®¡ç†å¿µï¼šé¿å…æŠ½å–â€œä¸å­˜åœ¨â€çš„å¹»è§‰å®ä½“ï¼Œåªä¿¡ä»» KG ä¸­çš„çœŸå®åå­—ã€‚
# ==============================================================================
class MusicEntityExtractor:
    """éŸ³ä¹é¢†åŸŸå®ä½“æŠ½å–å™¨"""

    def __init__(self):
        """
        åˆå§‹åŒ–å®ä½“æŠ½å–å™¨ï¼Œä»KGåŠ è½½å®ä½“åˆ—è¡¨ã€‚
        åŠ è½½ä¸‰ç±»å®ä½“ï¼šä½œå“ï¼ˆæ­Œæ›²ï¼‰ã€ä¸“è¾‘ã€äººç‰©ã€‚
        """
        self.songs = set()  # å­˜å‚¨æ‰€æœ‰æ­Œæ›²åï¼ˆæ¥è‡ª :ä½œå“ èŠ‚ç‚¹ï¼‰
        self.albums = set()  # å­˜å‚¨æ‰€æœ‰ä¸“è¾‘åï¼ˆæ¥è‡ª :ä¸“è¾‘ èŠ‚ç‚¹ï¼‰
        self.persons = set()  # å­˜å‚¨æ‰€æœ‰äººç‰©åï¼ˆæ¥è‡ª :äººç‰© èŠ‚ç‚¹ï¼‰
        self._load_entities_from_kg()

    def _load_entities_from_kg(self):
        """
        ã€ç§æœ‰æ–¹æ³•ã€‘ä» Neo4j çŸ¥è¯†å›¾è°±ä¸­åŠ è½½å…¨éƒ¨å®ä½“ã€‚
        æ‰§è¡Œä¸‰æ¡ Cypher æŸ¥è¯¢ï¼Œåˆ†åˆ«è·å–ä½œå“ã€ä¸“è¾‘ã€äººç‰©çš„ name å±æ€§ã€‚
        è‹¥è¿æ¥å¤±è´¥ï¼Œåˆ™æ¸…ç©ºé›†åˆï¼Œé¿å…åç»­å´©æºƒã€‚
        """
        try:
            db = get_db()
            try:
                with db.session() as session:
                    result = session.run("MATCH (n:ä½œå“) RETURN n.name AS name")
                    self.songs = {record["name"] for record in result}
                    print(f"åŠ è½½äº† {len(self.songs)} é¦–æ­Œæ›²")

                    result = session.run("MATCH (n:ä¸“è¾‘) RETURN n.name AS name")
                    self.albums = {record["name"] for record in result}
                    print(f"åŠ è½½äº† {len(self.albums)} ä¸ªä¸“è¾‘")

                    result = session.run("MATCH (n:äººç‰©) RETURN n.name AS name")
                    self.persons = {record["name"] for record in result}
                    print(f"åŠ è½½äº† {len(self.persons)} ä¸ªäººç‰©")
            finally:
                close_db(db)
        except Exception as e:
            print(f"è­¦å‘Š: åŠ è½½å®ä½“åˆ—è¡¨æ—¶å‡ºé”™: {e}")
            self.songs = set()
            self.albums = set()
            self.persons = set()

    def extract_entities(self, text: str) -> Dict[str, List[str]]:
        """
        ã€æ ¸å¿ƒæ–¹æ³•ã€‘åŸºäºè¯å…¸çš„æœ€å¤§åŒ¹é…å®ä½“æŠ½å–ï¼ˆDictionary-based NERï¼‰ã€‚
        è¾“å…¥ï¼šä»»æ„æ–‡æœ¬ï¼ˆå¦‚ LLM çš„å›ç­”ï¼‰
        è¾“å‡ºï¼šæŒ‰ç±»å‹åˆ†ç±»çš„å®ä½“åˆ—è¡¨ {"songs": [...], "albums": [...], "persons": [...]}
        ç­–ç•¥ï¼š
          - æŒ‰å®ä½“é•¿åº¦é™åºæ’åºï¼Œä¼˜å…ˆåŒ¹é…é•¿ä¸²ï¼ˆé˜²â€œé’èŠ±ç“·â€è¢«æ‹†æˆâ€œèŠ±ç“·â€ï¼‰
          - è®°å½•åŒ¹é…ä½ç½®ï¼Œé˜²æ­¢é‡å ï¼ˆå¦‚â€œå‘¨æ°ä¼¦â€å’Œâ€œæ°ä¼¦â€ï¼‰
        """
        entities = {"songs": [], "albums": [], "persons": []}
        all_entities = {
            "songs": sorted(self.songs, key=len, reverse=True),
            "albums": sorted(self.albums, key=len, reverse=True),
            "persons": sorted(self.persons, key=len, reverse=True)
        }
        matched_positions = set()

        for entity_type in ["songs", "albums", "persons"]:
            found_entities = []
            for entity in all_entities[entity_type]:
                pattern = re.escape(entity)
                matches = list(re.finditer(pattern, text, re.IGNORECASE))
                for match in matches:
                    start, end = match.span()
                    is_overlapped = any(
                        not (end <= ms or start >= me)
                        for ms, me in matched_positions
                    )
                    if not is_overlapped:
                        found_entities.append(entity)
                        matched_positions.add((start, end))
                        break  # æ¯ä¸ªåŒ¹é…ä½ç½®åªå–ä¸€æ¬¡
            entities[entity_type] = list(set(found_entities))
        return entities

    def extract_all_entities(self, text: str) -> List[str]:
        """
        ã€è¾…åŠ©æ–¹æ³•ã€‘æå–æ–‡æœ¬ä¸­æ‰€æœ‰ç±»å‹çš„å®ä½“ï¼ˆä¸åˆ†ç±»ï¼Œå»é‡ï¼‰ã€‚
        ç”¨é€”ï¼šå¿«é€Ÿè·å–æ‰€æœ‰æåŠçš„ KG å®ä½“ã€‚
        """
        entities_dict = self.extract_entities(text)
        return list(set(entities_dict["songs"] + entities_dict["albums"] + entities_dict["persons"]))


# ==============================================================================
# ğŸ”‘ å…¨å±€å¸¸é‡ï¼šRELATION_KEYWORDS â€”â€” å…³ç³»å…³é”®è¯æ˜ å°„è¡¨
# ä½œç”¨ï¼šä¸º fallback è§„åˆ™è·¯å¾„æä¾›å…³ç³»è§¦å‘è¯ã€‚
# æ ¼å¼ï¼š{å…³ç³»ç±»å‹: [å…³é”®è¯æ­£åˆ™æˆ–å­—ç¬¦ä¸²åˆ—è¡¨]}
# ==============================================================================
RELATION_KEYWORDS = {
    "æ­Œæ‰‹": ["æ¼”å”±", "å”±", "ä¸»å”±", "ç”±.*?æ¼”å”±", "æ¼”å”±è€…", "è°å”±"],
    "ä½œè¯": ["ä½œè¯", "å¡«è¯", "è¯ä½œè€…", "æ­Œè¯ç”±", "ä½œè¯äºº", "è°å†™çš„è¯"],
    "ä½œæ›²": ["ä½œæ›²", "è°±æ›²", "æ›²ä½œè€…", "ä½œæ›²äºº", "è°ä½œæ›²"]
}

ALLOWED_RELATIONS = {"æ­Œæ‰‹", "ä½œè¯", "ä½œæ›²"}


def _normalize_entity(text: str) -> str:
    if not text:
        return ""
    return text.replace("ã€Š", "").replace("ã€‹", "").strip()


def _clean_tail_candidate(tail: str) -> str:
    if not tail:
        return ""
    cleaned = _normalize_entity(tail)
    cleaned = re.sub(r"[A-Za-z0-9]+", "", cleaned)
    for sep in ["æ˜¯", "ä¸º", "ç”±"]:
        if sep in cleaned:
            cleaned = cleaned.split(sep)[-1]
    if "æˆå‘˜" in cleaned:
        cleaned = cleaned.split("æˆå‘˜")[-1]
    cleaned = cleaned.lstrip("çš„")
    for suffix in ["æ¼”å”±è€…", "æ¼”å”±", "ä¸»å”±", "æ­Œæ‰‹"]:
        if cleaned.endswith(suffix):
            cleaned = cleaned[: -len(suffix)]
    return cleaned.strip()


def _is_valid_tail(tail: str, extractor: MusicEntityExtractor, allow_ungrounded: bool) -> bool:
    if not tail:
        return False
    if not allow_ungrounded:
        return tail in extractor.persons
    if tail in extractor.persons:
        return True
    if len(tail) < 2 or len(tail) > 20:
        return False
    if re.search(r"[0-9A-Za-z]", tail):
        return False
    if any(bad in tail for bad in ["ä¸çŸ¥é“", "ä¸ç¡®å®š", "å¯èƒ½", "éœ€è¦", "ç­”æ¡ˆ", "ç”¨æˆ·", "æ­Œæ›²", "ä¸“è¾‘", "æ¼”å”±", "éŸ©å›½", "ä¸­å›½", "æ—¥æœ¬", "ç¾å›½", "ç”·å­", "å¥³å­", "ç»„åˆ", "æˆå‘˜"]):
        return False
    return True


def _extract_ungrounded_person_candidates(text: str, extractor: MusicEntityExtractor) -> List[str]:
    candidates = []
    for match in re.finditer(r"[\u4e00-\u9fff]{2,6}", text):
        candidate = _clean_tail_candidate(match.group(0))
        if candidate in extractor.songs or candidate in extractor.albums:
            continue
        if _is_valid_tail(candidate, extractor, allow_ungrounded=True):
            if candidate not in candidates:
                candidates.append(candidate)
    return candidates


# ==============================================================================
# ğŸ¤– å‡½æ•°ï¼š_call_llm_for_extraction â€”â€” è°ƒç”¨ LLM æ‰§è¡Œç»“æ„åŒ–ä¿¡æ¯æŠ½å–
# ä½œç”¨ï¼šé€šè¿‡ Ollama è°ƒç”¨æœ¬åœ° LLMï¼ˆå¦‚ qwen:7bï¼‰ï¼Œä¼ å…¥ Promptï¼Œè¦æ±‚å…¶è¾“å‡º JSONã€‚
# è¾“å…¥ï¼šPrompt å­—ç¬¦ä¸²
# è¾“å‡ºï¼šLLM è¿”å›çš„ç¬¬ä¸€è¡Œéç©ºæ–‡æœ¬ï¼ˆå·²æ¸…ç† Thinking... æ—¥å¿—ï¼‰
# æ³¨æ„ï¼šè¿™æ˜¯â€œè®© LLM è‡ªå·±åš NER+REâ€çš„æ ¸å¿ƒè°ƒç”¨ç‚¹ã€‚
# ==============================================================================
def _call_llm_for_extraction(prompt: str) -> str:
    """å†…éƒ¨å‡½æ•°ï¼šè°ƒç”¨ LLM æ‰§è¡ŒæŠ½å–"""
    try:
        result = subprocess.run(
            ["ollama", "run", "qwen2.5:1.5b", prompt],
            capture_output=True,
            text=True,
            timeout=60,
            encoding='utf-8',
            creationflags=subprocess.CREATE_NO_WINDOW if sys.platform == "win32" else 0
        )
        output = result.stdout.strip()
        output = re.sub(r'^Thinking\.\.\.\s*', '', output, flags=re.MULTILINE)
        output = re.sub(r'\.{3}done thinking.*$', '', output, flags=re.MULTILINE)
        return output.split('\n')[0].strip()
    except Exception as e:
        print(f"[EXTRACTION ERROR] {e}")
        return ""


# ==============================================================================
# ğŸ§© å‡½æ•°ï¼šextract_triples_from_llm_answer â€”â€” ä¸»ä¸‰å…ƒç»„æŠ½å–å…¥å£
# ä½œç”¨ï¼šä» LLM çš„è‡ªç„¶è¯­è¨€å›ç­”ä¸­ï¼ŒæŠ½å–å‡ºç»“æ„åŒ–ä¸‰å…ƒç»„ [(head, relation, tail)]ã€‚
# ç­–ç•¥ï¼ˆæ··åˆå¼ï¼‰ï¼š
#   1ï¸âƒ£ ä¸»è·¯å¾„ï¼šè®© LLM è¾“å‡º JSONï¼ˆç«¯åˆ°ç«¯ NER+REï¼‰
#   2ï¸âƒ£ è½»é‡è§„åˆ™ï¼šå¤„ç†â€œæ–¹æ–‡å±±â€è¿™ç±»çŸ­ç­”æ¡ˆ
#   3ï¸âƒ£ Fallbackï¼šå…³é”®è¯ + å®ä½“åŒ¹é…ï¼ˆå…œåº•ï¼‰
# è¾“å…¥ï¼šllm_answerï¼ˆLLM å›ç­”æ–‡æœ¬ï¼‰ï¼Œquestionï¼ˆåŸå§‹é—®é¢˜ï¼Œç”¨äºä¸Šä¸‹æ–‡ï¼‰
# è¾“å‡ºï¼šä¸‰å…ƒç»„åˆ—è¡¨ï¼Œå¦‚ [("é’èŠ±ç“·", "ä½œè¯", "æ–¹æ–‡å±±")]
# ==============================================================================
def extract_triples_from_llm_answer(
    llm_answer: str,
    question: str = "",
    allow_ungrounded: bool = False
) -> List[Tuple[str, str, str]]:
    if not llm_answer or llm_answer.strip().lower() in {"æœªçŸ¥", "unknown", ""}:
        return []

    extractor = get_entity_extractor()
    forced_head = ""
    if allow_ungrounded and question:
        from handler import extract_head_entity
        forced_head = extract_head_entity(question)

    # === ç¬¬ä¸€æ­¥ï¼šå°è¯•ç”¨ LLM æŠ½å–ï¼ˆä¸»è·¯å¾„ï¼‰===
    extraction_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä¿¡æ¯æŠ½å–ç³»ç»Ÿã€‚è¯·ä»ä»¥ä¸‹æ–‡æœ¬ä¸­ï¼š
1. è¯†åˆ«ã€æ­Œæ›²ã€‘å’Œã€äººç‰©ã€‘å®ä½“ï¼›
2. åˆ¤æ–­å®ƒä»¬ä¹‹é—´çš„å…³ç³»ï¼Œå…³ç³»ç±»å‹åªèƒ½æ˜¯ï¼šæ­Œæ‰‹ã€ä½œè¯ã€ä½œæ›²ï¼›
3. è¾“å‡ºä¸¥æ ¼ä¸º JSON åˆ—è¡¨ï¼Œæ ¼å¼ï¼š[{{"head":"æ­Œæ›²","relation":"å…³ç³»","tail":"äººç‰©"}}]

ç¤ºä¾‹ï¼š
æ–‡æœ¬ï¼šã€Šé’èŠ±ç“·ã€‹ç”±å‘¨æ°ä¼¦æ¼”å”±ï¼Œæ–¹æ–‡å±±ä½œè¯ã€‚
è¾“å‡ºï¼š
[{{"head": "é’èŠ±ç“·", "relation": "æ­Œæ‰‹", "tail": "å‘¨æ°ä¼¦"}}, {{"head": "é’èŠ±ç“·", "relation": "ä½œè¯", "tail": "æ–¹æ–‡å±±"}}]

æ–‡æœ¬ï¼š{llm_answer}
è¾“å‡ºï¼š
"""

    raw_output = _call_llm_for_extraction(extraction_prompt)
    triples = []
    try:
        json_match = re.search(r'(\[.*\])', raw_output, re.DOTALL)
        if json_match:
            data = json.loads(json_match.group(1))
            for item in data:
                head = _normalize_entity(item.get("head", ""))
                rel = item.get("relation", "").strip()
                tail = _normalize_entity(item.get("tail", ""))
                if allow_ungrounded:
                    tail = _clean_tail_candidate(tail)
                if allow_ungrounded and not head and forced_head:
                    head = forced_head
                if rel in ALLOWED_RELATIONS:
                    if allow_ungrounded:
                        if head and _is_valid_tail(tail, extractor, allow_ungrounded=True):
                            triples.append((head, rel, tail))
                    elif (head in extractor.songs or head in extractor.albums) and tail in extractor.persons:
                        triples.append((head, rel, tail))
        if triples:
            return triples
    except Exception as e:
        print(f"[LLM EXTRACTION FAILED] {e}. Trying fallback...")

    # === ç¬¬äºŒæ­¥ï¼šLLM å¤±è´¥ â†’ å¯ç”¨è½»é‡è§„åˆ™æŠ½å– ===
    print("[INFO] Fallback to lightweight extraction.")
    light_triples = _lightweight_extraction(
        llm_answer,
        question,
        extractor,
        allow_ungrounded=allow_ungrounded
    )
    if light_triples:
        return light_triples

    # === ç¬¬ä¸‰æ­¥ï¼šå†èµ°å…³é”®è¯å…œåº• ===
    print("[INFO] Fallback to regex-based extraction.")
    return _fallback_regex_extraction(
        llm_answer,
        extractor,
        allow_ungrounded=allow_ungrounded
    )


# ==============================================================================
# ğŸª å‡½æ•°ï¼š_lightweight_extraction â€”â€” è½»é‡è§„åˆ™æŠ½å–ï¼ˆé’ˆå¯¹çŸ­ç­”æ¡ˆä¼˜åŒ–ï¼‰
# ä½œç”¨ï¼šå½“ LLM ç›´æ¥å›ç­”â€œæ–¹æ–‡å±±â€æ—¶ï¼Œç»“åˆé—®é¢˜ä¸Šä¸‹æ–‡æ„é€ ä¸‰å…ƒç»„ã€‚
# æµç¨‹ï¼š
#   1. ä» question æå–æ­Œæ›²åï¼ˆä½¿ç”¨ handler.py ä¸­çš„ç»Ÿä¸€é€»è¾‘ï¼‰
#   2. ä» llm_answer æå–å¹²å‡€äººåï¼ˆå»æ‹¬å·ã€å»å‰ç¼€ã€å»å°¾æ ‡ç‚¹ï¼‰
#   3. æ„é€  (song, relation, person)
# ä¼˜åŠ¿ï¼šé€Ÿåº¦å¿«ã€å‡†ç¡®ç‡é«˜ï¼Œé€‚ç”¨äºç®€å•é—®ç­”ã€‚
# ==============================================================================
def _lightweight_extraction(
    text: str,
    question: str,
    extractor: MusicEntityExtractor,
    allow_ungrounded: bool = False
) -> List[Tuple[str, str, str]]:
    from handler import get_relation_type_from_question, extract_head_entity  # â† å…³é”®ï¼šç»Ÿä¸€ head æå–

    rel = get_relation_type_from_question(question)
    if not rel:
        return []

    # âœ… ä½¿ç”¨ä¸ query_handler å®Œå…¨ä¸€è‡´çš„ head æå–æ–¹å¼ï¼
    song = extract_head_entity(question)
    if not song or song not in extractor.songs:
        return []

    clean_ans = text.strip()
    clean_ans = re.sub(r'\*+', '', clean_ans)
    clean_ans = re.split(r'[ã€‚ï¼ï¼Ÿ\n]', clean_ans)[0].strip()

    # æ¸…ç†å°¾éƒ¨æ ‡ç‚¹ã€æ‹¬å·ã€ç©ºæ ¼
    clean_tail = re.sub(r'[ã€‚ï¼ï¼Ÿï¼Œ,.\sã€‘ï¼‰\)\]]+$', '', clean_ans).strip()
    if allow_ungrounded:
        clean_tail = _clean_tail_candidate(clean_tail)

    REL_VARIANTS = {
        "ä½œè¯": ["ä½œè¯", "ä½œè¯äºº", "è¯ä½œè€…", "å¡«è¯äºº", "å¡«è¯"],
        "ä½œæ›²": ["ä½œæ›²", "ä½œæ›²äºº", "æ›²ä½œè€…", "è°±æ›²äºº", "è°±æ›²"],
        "æ­Œæ‰‹": ["æ­Œæ‰‹", "æ¼”å”±è€…", "ä¸»å”±", "æ¼”å”±"]
    }
    variants = REL_VARIANTS.get(rel, [rel])

    # çŸ­ç­”æ¡ˆç›´æ¥è¿”å›ï¼ˆå¦‚æœåœ¨ KG ä¸­ï¼‰
    if len(clean_tail) <= 20 and not any(
            w in clean_tail for w in ["ä¸çŸ¥é“", "ä¸ç¡®å®š", "å¯èƒ½", "éœ€è¦", "å—¯", "å¥½çš„", "ç”¨æˆ·"]) \
            and song not in clean_tail and not any(v in clean_tail for v in variants):
        if _is_valid_tail(clean_tail, extractor, allow_ungrounded):
            return [(song, rel, clean_tail)]

    # æ„å»ºæ­£åˆ™ patterns
    patterns = []
    for v in variants:
        patterns.append(r'ã€Š?{}ã€‹?\s*çš„\s*{}(?:æ˜¯|ä¸º)?\s*([^\sã€‚ï¼Œï¼›ï¼ï¼Ÿã€,ï¼Œ]+)'.format(re.escape(song), re.escape(v)))
        patterns.append(r'{}(?:æ˜¯|ä¸º)?\s*([^\sã€‚ï¼Œï¼›ï¼ï¼Ÿã€,ï¼Œ]+)'.format(re.escape(v)))
    patterns.append(r'ç­”æ¡ˆ[ï¼š:]\s*([^\sã€‚ï¼Œï¼›ï¼ï¼Ÿã€,ï¼Œ]+)')

    for pattern in patterns:
        match = re.search(pattern, clean_ans)
        if match:
            tail = match.group(1).strip()
            tail = re.split(r'[ï¼ˆ\(ã€\s]', tail)[0].strip()
            tail = re.sub(r'[ã€‚ï¼ï¼Ÿï¼Œ,.\sã€‘ï¼‰\)\]]+$', '', tail).strip()
            if allow_ungrounded:
                tail = _clean_tail_candidate(tail)
            if _is_valid_tail(tail, extractor, allow_ungrounded):
                return [(song, rel, tail)]
    return []


# ==============================================================================
# ğŸ›Ÿ å‡½æ•°ï¼š_fallback_regex_extraction â€”â€” å…³é”®è¯è§„åˆ™å…œåº•æŠ½å–
# ä½œç”¨ï¼šå½“ LLM å’Œè½»é‡è§„åˆ™éƒ½å¤±è´¥æ—¶ï¼Œç”¨å…³é”®è¯è§¦å‘å…³ç³»ï¼Œç»“åˆ KG å®ä½“åŒ¹é…ã€‚
# ç­–ç•¥ï¼š
#   - head å¿…é¡»æ¥è‡ª KGï¼ˆç¡®ä¿ä¸»ä½“æ­£ç¡®ï¼‰
#   - tail **åªä½¿ç”¨ KG ä¸­å‡ºç°è¿‡çš„äººç‰©**ï¼ˆä¸å†çŒœæµ‹ï¼ï¼‰
#   - æ¯ç§å…³ç³»åªå–ç¬¬ä¸€ä¸ªåˆç† tail
# å®šä½ï¼šæœ€åé˜²çº¿ï¼Œä¿è¯ç³»ç»Ÿä¸å´©æºƒã€‚
# ==============================================================================
def _fallback_regex_extraction(
    text: str,
    extractor: MusicEntityExtractor,
    allow_ungrounded: bool = False
) -> List[Tuple[str, str, str]]:
    entities = extractor.extract_entities(text)
    songs = entities["songs"]
    if not songs:
        return []

    # âœ… å…³é”®ä¿®å¤ï¼šåªä½¿ç”¨ KG ä¸­å­˜åœ¨çš„äººç‰©ï¼Œæ‹’ç»ä¹±çŒœï¼
    persons_in_text = [p for p in extractor.persons if p in text]
    if not persons_in_text and not allow_ungrounded:
        return []  # å¦‚æœæ²¡æåˆ°ä»»ä½• KG äººç‰©ï¼Œç›´æ¥æ”¾å¼ƒ

    if persons_in_text:
        candidate_tails = persons_in_text
    else:
        candidate_tails = _extract_ungrounded_person_candidates(text, extractor)
        if not candidate_tails:
            return []
    triples = []
    cleaned_text = _normalize_entity(text)

    for song in songs:
        for rel_type, keywords in RELATION_KEYWORDS.items():
            for kw in keywords:
                pattern = kw if kw.startswith("ç”±") else re.escape(kw)
                if re.search(pattern, cleaned_text, re.IGNORECASE):
                    for tail in candidate_tails:
                        if tail == song:
                            continue
                        triples.append((song, rel_type, tail))
                        break
                    break
    return triples


# ==============================================================================
# ğŸ§¾ å‡½æ•°ï¼šget_entity_extractor â€”â€” å•ä¾‹æ¨¡å¼è·å–å®ä½“æŠ½å–å™¨
# ä½œç”¨ï¼šå…¨å±€åªåŠ è½½ä¸€æ¬¡ KG å®ä½“ï¼Œé¿å…é‡å¤è¿æ¥æ•°æ®åº“ã€‚
# è¿”å›ï¼šMusicEntityExtractor å®ä¾‹
# ==============================================================================
_extractor_instance = None


def get_entity_extractor() -> MusicEntityExtractor:
    """è·å–å®ä½“æŠ½å–å™¨å•ä¾‹"""
    global _extractor_instance
    if _extractor_instance is None:
        _extractor_instance = MusicEntityExtractor()
    return _extractor_instance
